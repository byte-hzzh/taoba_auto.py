1.设计之初的目的是，收集购物网站的订单信息，并将其分类,写入excel文件或者mysql数据库进行保存，通过这些订单信息，统计每个月的开销、常买物品等等。

2.对购物网站的登陆页面分析,分为用户名、密码登录和扫码登录，为了避免多次密码登录对账号产生不良影响，所以采用扫码登录，这里就需要使用selenium，selenium能够开启一个浏览器，用代码执行日常人为的操作。为了避免在扫码登陆时，程序还在后台运行，这边使用input()函数阻塞程序，登陆完成后，在控制台按下回车键，便可让程序正常运行。在订单详情页分析后,发现订单页的URL存放在相关标签中,使用CSS选择器定位标签,对目标网页分析后,发现由于爬取的数据太多,网页界面存在旧版本、新版本,所以得分类分策略爬取数据,并对不满足要求的数据剔除。在程序中加入筛选日期，加入input函数，输入想要查询的8位数时间日期，将订单左上角旁的时间，字符串转换为年月日8位数字，对要查找的时间进行比较，收集目标时间后的相关订单。

3.在对网页数据爬取时发现，经常在 跳转下一页进行数据采集时报错，未找到对应元素，这边在跳转页面后加入休眠时间，解决了此类问题。为了更方便的观察程序运行情况,导入tqdm包,通过进度条直观观察程序运行,在对程序运行速度的研究下,发现将网页加载方式改为‘eager’能够较快加速程序运行,后续运行中,使用selenium无头模式运行,使用截屏功能截取登录二维码,导入Image包,使用Image包打开相关图片,进行扫码登陆操作，大大加快采集效率。在对目标数据的匹配上,使用str.find()函数,通过find未找到相关字符串返回-1的特性,剔除相关数据。